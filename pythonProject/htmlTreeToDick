import time
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from bs4 import BeautifulSoup
import re
from selenium.webdriver.common.by import By

makeDict = dict()
top_code_list = dict()
tag_list = ''


def nodeMaker(key, value):  # 키 노드를 만든다
    global makeDict
    try:
        if str(key) not in makeDict:
            if len(key) == 1:
                makeDict[key] = dict()
            elif len(key) == 3:
                makeDict[key[:1]][key] = dict()
            elif len(key) == 4:
                makeDict[key[:1]][key[:3]][key] = dict()
            elif len(key) == 5:
                if type(makeDict[key[:1]][key[:3]][key[:4]]) is list:
                    makeDict[key[:1]][key[:3]][key[:4]].append({key : [value]})
                else:
                    makeDict[key[:1]][key[:3]][key[:4]][key] = dict()
                print(type(makeDict[key[:1]][key[:3]][key[:4]]), '/=>', key)
            elif len(key) == 6:
                print('number 6 ?')
    finally:
        print(key, makeDict)


def makeCodeName():  # 코드 한글 변환 콜렉션을 만든다.
    global top_code_list
    global tag_list
    if tag_list:
        fisrst_titles = tag_list.select('body > ul > li > div.list.selected > a')
        second_titles = tag_list.select('body > ul > li > ul > li > div.list > a')
        third_titles = tag_list.select('body > ul > li > ul > li > ul > li > div.list > a')
        fourth_titles = tag_list.select('body > ul > li > ul > li > ul > li > ul > li > div.list > a')

        if fisrst_titles:
            for title in fisrst_titles:
                top_code_list[title.parent.parent.attrs['id']] = title.text
        else:
            print('비었음 fisrst_titles')

        if second_titles:
            for title2 in second_titles:
                top_code_list[title2.parent.parent.attrs['id']] = title2.text
        else:
            print('비었음 second_titles')

        if third_titles:
            for title3 in third_titles:
                top_code_list[title3.parent.parent.attrs['id']] = title3.text
        else:
            print('비었음 third_titles')

        if fourth_titles:
            for title4 in fourth_titles:
                top_code_list[title4.parent.parent.attrs['id']] = title4.text
        else:
            print('비었음 fourth_titles')
    else:
        print('비었음 tag_list')


def makeBodyCollection(keyChar):  # 데이터 콜렉션을 만든다

    global tag_list
    second_titles = tag_list.select('li[id^="' + keyChar + '"]')

    if second_titles:
        for (index, title) in enumerate(second_titles):
            key = title.attrs['id']
            value = title.select_one('div.list > a').text
            nodeMaker(key, value)
            sub = title.select('ul[id^="ul' + key + '"] > li:not([id]) > a')

            if sub:
                for st in sub:
                    s_key = st.parent.parent.attrs['id'][2:]
                    s_value = st.text
                    if key == s_key:
                        if len(key) == 4:
                            if makeDict[key[:1]][key[:3]][s_key]:
                                makeDict[key[:1]][key[:3]][s_key].append(s_value)
                            else:
                                makeDict[key[:1]][key[:3]][s_key] = list()
                                makeDict[key[:1]][key[:3]][s_key].append(s_value)
                        elif len(key) == 5:
                            if type(makeDict[key[:1]][key[:3]][key[:4]]) is list:  # 삽입하려는 윗놈이 리스트다 -> 어떻게 하지?
                                # s_key을 확인하여서 존재하는 경우와 그렇지 않은 경우 처리를 분류 해야 함. 아래 else 처럼
                                for (i, test) in enumerate(makeDict[key[:1]][key[:3]][key[:4]]):
                                    if s_key in test:
                                        makeDict[key[:1]][key[:3]][key[:4]][i][s_key].append(s_value)
                            else:
                                if makeDict[key[:1]][key[:3]][key[:4]][s_key]:
                                    makeDict[key[:1]][key[:3]][key[:4]][s_key].append(s_value)
                                else:
                                    makeDict[key[:1]][key[:3]][key[:4]][s_key] = list()
                                    makeDict[key[:1]][key[:3]][key[:4]][s_key].append(s_value)
            else:
                print('비었음 2')
    else:
        print('비었음 1')


try:
    page = open('D:/PycharmProjects/pythonProject/yahyo.html', 'r', encoding='UTF8')
    soup = BeautifulSoup(page, 'html5lib')  # html5lib ,  lxml
    tag_list = soup.find('ul', class_='depth01')
    makeCodeName()  # 코드네임표 만들기

    charList = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Z']
    for charX in charList:  # 크롤링 시작
        makeBodyCollection(charX)

    print(makeDict)

finally:
    # print(top_code_list)
    print('END')

# 절대 주소를 알고 있는경우 Bs4 쓰는게 훨씬 빠르다.
# 복잡하게 다단계 + 로그인 처리등을 해야 하는 경우에만 셀레늄을 사용하는게 좋을 듯

# 네이버 로그인은 힘들다고 한다.. win32.api 쓰면 된다고 하는데
# send_key() 함수를 사용하면 캡차로 직행하니 피하고
# 키보드를 입력하는 것럼 또는 ctrl+v 로 넣는 경우에는
# 알아차리지 못한다고 한다.

# 사이트 charset 상관없이 파싱해오기
# url = "http://www.yes24.com/searchcorner/Search?keywordAd=&keyword=&domain=BOOK&qdomain=%B1%B9%B3%BB%B5%B5%BC%AD&query=%C6%C4%C0%CC%BD%E3"
# with request.urlopen(url) as f:
#   charset = f.headers.get_content_charset() //해당 사이트 charset을 뽑아서 처리
#   html = f.read().decode(charset)

# bs4 활용법
# find 의 목적은 원하는 태그를 찾는 것이다.
# 태그 이름만 특정 soup.find('p')
# 태그 속성만 특정 soup.find(class_='youngone') soup.find(attrs = {'class':'youngone'})
# 태그 이름과 속성 모두 특정 soup.find('p', class_='youngone')
# tag = "<p class='youngone' id='junu'> Hello World! </p>"
# 태그의 이름 object_tag.name => #결과: 'p'
# #태그에 담긴 텍스트 object_tag.text => #결과: ' Hello World! '
# #태그의 속성과 속성값 object_tag.attrs => #결과: {'class': ['youngone'], 'id': 'junu'}

# 셀레니움 활용법

# driver.find_element(By.XPATH, '//button[text()="Some text"]')
# driver.find_elements(By.XPATH, '//button')
# By.XPATH = "xpath"
# By.LINK_TEXT = "link text"
# By.PARTIAL_LINK_TEXT = "partial link text"
# By.NAME = "name"
# By.TAG_NAME = "tag name"
# By.CLASS_NAME = "class name"
# By.CSS_SELECTOR = "css selector"

# 키조작 element.send_keys(" and some", Keys.ARROW_DOWN)
# 엘리먼트 클리어 : element.clear() , 삭제가 아니고 입력되어 있는 내용을 지움

# headness 모드 발동
# options = Options()
# options.headless = True  # 크롬 UI 실행 여부, True 가 속도가 아무래도 빠르다
# options.add_argument("--window-size=400,400")

# 드라이버 세팅
# pageDriver = webdriver.Chrome(options=options, executable_path='D:\PycharmProjects\pythonProject\chromedriver')

# 페이지 가져오기
# pageDriver.get('file:///D:/PycharmProjects/pythonProject/yahyo.html')

# 전체 소스 pageDriver.page_source

# 앞뒤로 히스토리 이용
# driver.forward()
# driver.back()

# 쿠키처리
# driver.add_cookie(cookie) // {‘name’ : ‘foo’, ‘value’ : ‘bar’}
# And now output all the available cookies for the current URL
# driver.get_cookies()

# for element in self.driver.find_elements_by_tag_name('img'):
#        print element.text
#        print element.tag_name
#        print element.parent
#        print element.location
#        print element.size

# href 링크 가져오기
# div.find_element_by_css_selector('a').get_attribute('href')
# ids = self.driver.find_elements_by_xpath('//*[@href]')
#    for id in ids:
#         print(id.get_attribute('href'))

# 페이지 이동후 새로운 페이지 주소 가져오기
# newURl = driver.window_handles[0]

# 새로운 페이지로 작업 페이지 업데이트 시키기
# driver.switch_to.window(newURl)

# Get element with tag name 'div'
#   element = driver.find_element(By.TAG_NAME, 'div')

# Get all the elements available with tag name 'p'
#   elements = element.find_elements(By.TAG_NAME, 'p')
#   for e in elements:
#        print(e.text)

# 활성화 여부 확인
# value = driver.find_element(By.NAME, 'btnK').is_enabled()

# 체크 여부 확인
# value = driver.find_element(By.CSS_SELECTOR, "input[type='checkbox']:first-of-type").is_selected()

# position
# res = driver.find_element(By.CSS_SELECTOR, "h1").rect

# css info
# cssValue = driver.findElement(By.LINK_TEXT, "More information...").value_of_css_property('color')

# text
# text = driver.find_element(By.CSS_SELECTOR, "h1").text

# <class 'selenium.webdriver.remote.webelement.WebElement'>
# webElement
# Accessing the text of the element with the property element.text
# Clicking on the element with element.click()
# Accessing an attribute with element.get_attribute('class')
# Sending text to an input: element.send_keys('mypassword')
# There are some other interesting methods like is_displayed()
# , it returns True if an element is visible to the user.
# wait for page usage
# try:
#     element = WebDriverWait(driver, 10).until(  EC.presence_of_element_located((By.ID, "myDynamicElement"))) // ID myDynamicElement 가 나타날때 까지 대기를 10초간 한다.
# finally:
#     driver.quit()
# xpath => driver.find_element_by_xpath("/html/body/form[1]")
# <html>
#  <body>
#   <form id="loginForm">
#    <input name="username" type="text" />
#    <input name="password" type="password" />
#    <input name="continue" type="submit" value="Login" />
#    <input name="continue" type="button" value="Clear" />
#   </form>
# </body>
# <html>
# select , input using xpath
# username = driver.find_element_by_xpath("//form[input/@name='username']")
# username = driver.find_element_by_xpath("//form[@id='loginForm']/input[1]")
# username = driver.find_element_by_xpath("//input[@name='username']")
# driver.find_element_by_xpath("//input[@type='password']").send_keys(PASSWORD) 텍스트 입력
# driver.find_element_by_xpath("//input[@value='login']").click() 클릭

# hyper Links
# continue_link = driver.find_element_by_link_text('Continue')
# continue_link = driver.find_element_by_partial_link_text('Conti')

# css selector
# content = driver.find_element_by_css_selector('p.content')

# search_box = driver.find_element_by_name('q')
# search_box.send_keys('FireFox')
# search_box.submit()
# time.sleep(3)

# 최악의 경우
# Captchas 사용한 페이지 :
# 2FA (Two Factor Authentication) 사용한 경우
# 파일다운로드시 링크만 취하고 , 실제 다운로드는 libccurl 같은 걸로 처리 해라 (셀레니엄이 다운로드 프로세스 체크를 못한다고...)
# Http response codes 같은 경우 다른 상태로 나올수가 있다.(브라우저에 설정에 따른 처리 방식 차이)
# gmail / facebook 등, Dos 공격으로 오인받을 수 있음.
# 퍼포먼스 테스트용
# link spider 사용 -> scrapy 사용해라

# 아직까지 되는지 잘 모름...
# def clipboard_input(self, user_xpath, user_input):
#        pyperclip.copy(user_input) # input을 클립보드로 복사
#        self.driver.find_element_by_xpath(user_xpath).click() # element focus 설정
#        ActionChains(self.driver).key_down(Keys.CONTROL).send_keys('v').key_up(Keys.CONTROL).perform() # Ctrl+V 전달
#        time.sleep(1)

# for (index, x) in enumerate(tag_list.contents):
#    print(index, type(x), x)

# liList = parents.find_elements_by_tag_name('li')  # 최상위 <li id="A , B , C ... Z">
# link_list = cols[2].find_all('a', href=True)
# cols = [ele.text.strip() for ele in cols]
# result_data.append([ele for ele in cols if ele] + [aHref] + [aDownLoad])
# parents = pageDriver.find_elements_by_xpath('//*[@class="depth01"]')
# top_1_cates = parents.find_elements_by_xpath('//*[@id="A"]/div/a')
# print(len(top_1_cates))
# top_2_cates = parents.find_elements_by_xpath('//*[@id="B"]')
# username = driver.find_element_by_xpath("//form[input/@name='username']")
# username = driver.find_element_by_xpath("//form[@id='loginForm']/input[1]")
# username = driver.find_element_by_xpath("//input[@name='username']")
# 이동후 에는 페이지를 새롭게 가져와야 한다.
# newURl = pageDriver.window_handles[0]
# 이런방법도 있나봄
# driver.execute_script("window.open('"+url+"', '_blank');")
# driver.switch_to_window(driver.window_handles[1])
# print('newURl', newURl) -> newURl CDwindow-6BCDE71CD0B9CEA18638B4FC91C28D35
# pageDriver.switch_to.window(newURl)
# print(pageDriver.current_url)  # 이동한 페이지의 주소가 뜬다.
# pageDriver.quit()
